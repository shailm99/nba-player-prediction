{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cfc1e8b-77ad-4522-aac2-970b468f6425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0313f0f8-fb24-4013-bac5-c9fd30ac158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('merged_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60568fee-8942-4f50-8d86-2c9f62869c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only players with more than 10 games\n",
    "data = data[data.games_played >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b7675ef-d6cb-4fee-84b3-96a0a9007045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates - corresponds to players that were traded mid season\n",
    "data.drop_duplicates(subset=['name', 'year_end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0b56317-19ea-4110-a943-9a9bad2369e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train data set\n",
    "\n",
    "train = data[data.season != 2022]\n",
    "test = data[data.season == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15cb7416-f3d3-4665-ac92-8fc29a68abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually choose features to include in model \n",
    "\n",
    "features = ['age', 'player_efficiency_rating',\n",
    "       'true_shooting_percentage', 'three_point_attempt_rate',\n",
    "       'free_throw_attempt_rate', 'offensive_rebound_percentage',\n",
    "       'defensive_rebound_percentage', 'total_rebound_percentage',\n",
    "       'assist_percentage', 'steal_percentage', 'block_percentage',\n",
    "       'turnover_percentage', 'usage_percentage', 'offensive_win_shares',\n",
    "       'defensive_win_shares', 'win_shares', 'win_shares_per_48_minutes',\n",
    "       'offensive_box_plus_minus', 'defensive_box_plus_minus',\n",
    "       'box_plus_minus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6840df30-6e4f-4ebe-ae8d-6a9059047d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store features\n",
    "\n",
    "X_train = train[features]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785443a-b2c9-44d8-830e-dcbc0dffdd29",
   "metadata": {},
   "source": [
    "**QUESTION**\n",
    "\n",
    "Saw your note about possible feature pinpointing or reduction\n",
    "\n",
    "I considered doing PCA but I do not think dimension reductionality is neccessary for computation purposes\n",
    "\n",
    "However, doing analysis on first x PCA components could be something to throw in just for credit to show we understand material\n",
    "\n",
    "So I am thinking we could commit to capturing x% of the variance of the data and however many components that corresponds to\n",
    "\n",
    "Or we could do PCA for some models and not for others.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6e767bd-b9c6-406c-80c2-fbb22f097a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data - good for neural networks\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "\n",
    "# Fit only on training data\n",
    "\n",
    "scaler.fit(X_train)  \n",
    "X_train_standard = scaler.transform(X_train) \n",
    "\n",
    "# apply same transformation to test data\n",
    "\n",
    "X_test_standard = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ff56c9a-7f8c-4a47-ba15-c42196fed16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up grid search for alpha to tune hyperparameter\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "parameters = {'alpha': 10.0 ** -np.arange(1, 7)}\n",
    "\n",
    "network = MLPRegressor(hidden_layer_sizes=(25,25,25),\n",
    "                       max_iter = 2000,activation = 'tanh',\n",
    "                       solver = 'sgd',learning_rate='adaptive',\n",
    "                       early_stopping = True)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5737c2e-51d5-4a09-990b-2a3e2bb6506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conduct grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_neural = GridSearchCV(network,\n",
    "                      param_grid=parameters,\n",
    "                      scoring='neg_mean_absolute_error',\n",
    "                      cv=5, verbose=1)\n",
    "\n",
    "gs_neural.fit(X_train_standard, train['epm'])\n",
    "gs_neural.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a3c8df5-ecbf-4d3b-acbb-514dc317d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose tuned parameter\n",
    "\n",
    "best_network = MLPRegressor(hidden_layer_sizes=(25,25,25),\n",
    "                       max_iter = 2000,activation = 'tanh',\n",
    "                       solver = 'sgd',learning_rate='adaptive',\n",
    "                       alpha = gs_neural.best_params_['alpha'],\n",
    "                       early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58605f4b-3b87-48db-9eff-c4269520f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.53102728 -1.65404699 -1.52410067 -1.48828026 -1.52185443]\n",
      "1.5438619240197695\n"
     ]
    }
   ],
   "source": [
    "#cross validation scores on training for model with chosen hyperparameters\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = cross_val_score(best_network, X_train_standard, train['epm'], cv = 5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(cv)\n",
    "print(-1 * np.mean(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4de97b43-f0c6-45bc-99bf-5b0ff5b9e17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=0.1, early_stopping=True,\n",
       "             hidden_layer_sizes=(25, 25, 25), learning_rate='adaptive',\n",
       "             max_iter=2000, solver='sgd')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate test error\n",
    "#refit neural network\n",
    "\n",
    "#QUESTION:\n",
    "#should I refit here? it uses SGD so slightly different parameters\n",
    "#Or should I use same model as I used in CV\n",
    "#If i should use same model as CV caluclation, how do I do it?\n",
    "\n",
    "best_network.fit(X_train_standard, train['epm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c89c5974-7e55-43fb-a3e0-433ba2c2b6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0450988173042917"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = best_network.predict(X_test_standard)\n",
    "actual = test['epm']\n",
    "\n",
    "RSME = (sum((predictions - actual)**2)/len(actual))**0.5\n",
    "\n",
    "RSME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cfd76-1064-4443-ae12-14f6b15e5e58",
   "metadata": {},
   "source": [
    "I think we could use RSME on test data to compare different models and go from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded2e0d-f179-4260-94da-b30d7c459176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
